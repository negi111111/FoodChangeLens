<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
    <title>FoodChangeLens Project Page</title>
    <meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

    <script src="lib.js" type="text/javascript"></script>
    <script src="popup.js" type="text/javascript"></script>
    <link rel="stylesheet" type="text/css" href="css/style.css" />
    <style type="text/css" media="all">
        IMG {
            PADDING-RIGHT: 0px;
            PADDING-LEFT: 0px;
            FLOAT: right;
            PADDING-BOTTOM: 0px;
            PADDING-TOP: 0px
        }

        #primarycontent {
            MARGIN-LEFT: auto;
            ;
            WIDTH: expression(document.body.clientWidth > 1000? "1000px": "auto");
            MARGIN-RIGHT: auto;
            TEXT-ALIGN: left;
            max-width:
                1000px
        }

        BODY {
            TEXT-ALIGN: center
        }
    </style>

    <meta content="MSHTML 6.00.2800.1400" name="GENERATOR">
    <script src="b5m.js" id="b5mmain" type="text/javascript"></script>
</head>

<body>

    <div id="primarycontent">
        <center>
            <h1>FoodChangeLens: CNN-based Food Transformation on HoloLens</h1>
        </center>
        <center>
            <h2><a href="https://twitter.com/nenoMake">Shu Naritmo</a>&nbsp;&nbsp;&nbsp;
  <a href="https://negi111111.github.io/">Ryosuke Tanno</a>&nbsp;&nbsp;&nbsp;
  <a href="">Takumi Ege</a>&nbsp;&nbsp;&nbsp;
  <a href="http://acc.cs.uec.ac.jp/yanai/index.html">Keiji Yanai</a></h2>
        </center>
        <center>
            <h2><a href="http://mm.cs.uec.ac.jp/e/">Department of Informatics, The University of Electro-Communication</a></h2>
        </center>
        <center>
            <h2>In *** 2018</h2>
        </center>
        <p></p>

        <h2 align='center'></h2>
        <table border="0" align="center" cellspacing="0" cellpadding="20">
            <td align="center" valign="middle">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/yBM9VgXj9e0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </td>
        </table>

        <p>
<h2>Abstract</h2>

        <div style="font-size:14px">
            <p>In this demonstration, we implemented food category transformation in mixed reality using both image generation and HoloLens. Our system overlays transformed food images to food objects in the AR space, so that it is possible to convertin consideration of real shape. This system has the potential to make meals more enjoyable. In this work, we use the Conditional CycleGAN learned with a large-scale food image data collected from the Twitter Stream for food category transformation which can transform among ten kinds of foods mutually keeping the shape of a given food. We show the virtual meal experience that food category transformation among ten kinds of typical Japanese foods: ramen noodle, curry rice, fried rice, beef ricebowl, chilled noodle, spaghetti with meat source, white rice, eelbowl, and fried noodle.</p>
    </div>

    <a href=""><img style="float: left; padding: 10px; PADDING-RIGHT: 30px;" alt="paper thumbnail" src="images/paper_thumbnail.jpg" width=170></a>
    <br>



    <h2>Paper</h2>
    <p><a href="***">***</a>,  2018. </p>

    <h2>Citation</h2>
    <p>Shu Naritomi, Ryosuke Tanno, Takumi Ege, and Keiji Yanai. "FoodChangeLens:CNN-based Food Transformation on HoloLens", in ***, 2018.
<a href="FoodChangeLens.txt">Bibtex</a>

</p>
    <br>

    <!-- <h2 align='center'> Expository Articles and Videos </h2>
    <table border="0" cellspacing="0" cellpadding="20">
        <td align="center" valign="middle">
            <h2>Two minute papers</h2>
            <p><iframe width="480" height="270" src="https://www.youtube.com/embed/D4C1dB9UheQ" frameborder="0" allowfullscreen></iframe></p>
            <div style="width:480px; text-align:left; font-size:14px">Karoly Zsolnai-Feher made the above as part of his very cool <a href="https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg">"Two minute papers"</a> series.</div>
        </td>

        <td align="center" valign="middle">
            <h2>Understanding and Implementing CycleGAN</h2>
            <p><a href="https://hardikbansal.github.io/CycleGANBlog/"><img src="images/cyclegan_blogs.jpg"  width=480 height=270> </a></p>
            <div style="width:480px; text-align:left; font-size:14px">Nice explanation by Hardik Bansal and Archit Rathore, with Tensorflow code documentation.</div>
        </td>

        </tr>
    </table>  -->


    <br><br><br>
    <h2>Related Work</h2>

    <ul id='relatedwork'>
        <li>
            Y. Matsuda, H. Hoashi, and K. Yanai <a href=""><strong>"Recognition of multiple-food
                    images by detecting candidate regions"</strong></a>, in ICME 2012.
        </li>
        <li>
            O. Ronneberger, P. Fischer, and T. Brox <a href=""><strong>"U-Net: Convolutional Networks
                    for Biomedical Image Segmentation"</strong></a>, in Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2015.
        </li>
        <li>
            J. Y. Zhu, T. Park, P. Isola, and A. A. Efros <a href=""><strong>"Unpaired Image-to-Image
                    Translation using Cycle-Consistent Adversarial Networks"</strong></a>, in ICCV 2017.
        </li>
    </ul>


    <br>
    <h2>Acknowledgement</h2>
    <p>This work was supported by JSPS KAKENHI Grant Number 15H05915, 17H01745, 17H05972, 17H06026 and 17H06100.</p>

</body>
</html>
